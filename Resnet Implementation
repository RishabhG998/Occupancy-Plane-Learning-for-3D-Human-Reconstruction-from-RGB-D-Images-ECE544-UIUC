{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Bz4nXp1Q8dNO"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import glob\n","from skimage import io\n","import cv2"]},{"cell_type":"code","source":["DATA_PATH = '/content/drive/MyDrive/ECE 544 Project/Vincent\\'s Workspace/demodata/ac_ig_3_p3_b/images/*.bmp'\n","BATCH_SIZE = 32\n","LEARNING_RATE = 1e-3\n","NUM_EPOCHS = 5\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"uMUmgMrkkhwT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PRDataLoader(Dataset):\n","  def __init__(self, path):\n","    self.image_paths = []\n","    for f in glob.glob(DATA_PATH, recursive=True):\n","      self.image_paths.append(f)\n","    \n","  def __len__(self):\n","    return len(self.image_paths)\n","  \n","  def __getitem__(self, index):\n","    image_path = self.image_paths[index]\n","    image = io.imread(image_path)\n","    image = cv2.resize(image, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n","    image = torch.tensor(image).permute(2, 0, 1)\n","    image = image / 255.\n","    label = 1\n","    return (image, label)"],"metadata":{"id":"aaAqJHyajpcz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = PRDataLoader(DATA_PATH)\n","train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"],"metadata":{"id":"aC8QDiaPm5FN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RGB(nn.Module):\n","  def __init__(self, in_channels):\n","    super(CNN,self).__init__()\n","    self.conv1 = nn.Conv2d(in_channels=256,out_channels=128,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n","    self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n","    self.conv2 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n","    self.fc1 = nn.Linear(128*128*1)\n","\n","  def forward(self,x):\n","    x = F.relu(self.conv1(x))\n","    x = self.pool(x)\n","    x = F.relu(self.conv2(x))\n","    x = self.pool(x)\n","    x = x.reshape(x.shape[0],-1)\n","    x = self.fc1(x)\n","\n","    return x\n","\n","model = RGB()\n","\n","\n"],"metadata":{"id":"S_AhxMAeo7fV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torchvision.models.resnet18(pretrained=True)\n","model.to(DEVICE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQhKAJXnoet5","executionInfo":{"status":"ok","timestamp":1665553714155,"user_tz":300,"elapsed":143,"user":{"displayName":"Rishabh Garg","userId":"04708700132106046001"}},"outputId":"05e0893f-d1ec-4f7d-cd0d-3178ab58d143"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"],"metadata":{"id":"deOo5pCgoero"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(NUM_EPOCHS):\n","  losses = []\n","  for x_batch, y_batch in train_loader:\n","    x_batch = x_batch.to(DEVICE)\n","    y_batch = y_batch.to(DEVICE)\n","\n","    y_pred = model(x_batch)\n","\n","    loss = criterion(y_pred, y_batch)\n","    losses.append(loss)\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  print(losses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9lssg0kDoeo7","executionInfo":{"status":"ok","timestamp":1665553723755,"user_tz":300,"elapsed":8522,"user":{"displayName":"Rishabh Garg","userId":"04708700132106046001"}},"outputId":"7980d596-3edd-4751-9c7b-813c73d7a8a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor(8.2541, grad_fn=<NllLossBackward0>)]\n","[tensor(7.8280, grad_fn=<NllLossBackward0>)]\n","[tensor(5.0331, grad_fn=<NllLossBackward0>)]\n","[tensor(2.7771, grad_fn=<NllLossBackward0>)]\n","[tensor(1.4798, grad_fn=<NllLossBackward0>)]\n"]}]},{"cell_type":"code","source":["test_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n","with torch.no_grad():\n","  predictions = []\n","  for x_batch, y_batch in test_loader:\n","    x_batch = x_batch.to(DEVICE)\n","    y_batch = y_batch.to(DEVICE)\n","    y_pred = model(x_batch)\n","    _, prediction = y_pred.max(1)\n","    predictions.extend(prediction)\n","  print(predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4mivOClrMtt","executionInfo":{"status":"ok","timestamp":1665553724731,"user_tz":300,"elapsed":994,"user":{"displayName":"Rishabh Garg","userId":"04708700132106046001"}},"outputId":"408c0f15-595a-48d1-8af0-2ca4f1ec93bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor(1), tensor(1), tensor(1)]\n"]}]},{"cell_type":"code","source":["class FSpatial(nn.Module):\n","  def __init__(self, in_channels):\n","    super(CNN,self).__init__()\n","    self.conv1 = nn.Conv2d(in_channels=256,out_channels=128,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n","    self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n","    self.conv2 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n","    self.fc1 = nn.Linear(128*1*1)\n","\n","  def forward(self,x):\n","    x = F.relu(self.conv1(x))\n","    x = self.pool(x)\n","    x = F.relu(self.conv2(x))\n","    x = self.pool(x)\n","    x = x.reshape(x.shape[0],-1)\n","    x = self.fc1(x)\n","\n","    return x\n","\n","input_size=\n","epochs=\n","learning_rate=\n","batch_size=\n","\n","model = FSpatial(input_size=input_size).to(DEVICE)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(Model.parameters(),lr=learning_rate)\n","\n"],"metadata":{"id":"9UqSEgk3s4-x"},"execution_count":null,"outputs":[]}]}